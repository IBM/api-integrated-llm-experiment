{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib\n",
    "import os\n",
    "#os.chdir(\"/dccstor/arnaik_data/routing/model-improvement/data\")\n",
    "os.chdir(\"/Users/benjaminelder/ai4ba\")\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder=\"results\"\n",
    "categories=[\"llms\",\"agents\"]\n",
    "groups=[\"slot_filling\",\"sequencing\"] #,\"rest\"]\n",
    "aggregation_filename=\"metrics_aggregation\"\n",
    "version='v3'\n",
    "model_names_llms=[\n",
    "    \"llama-3-3-70b-instruct\",\n",
    "    \"Llama-3.1-8B-Instruct\",\n",
    "    \"Mixtral-8x22B-Instruct-v0.1\",\n",
    "    \"DeepSeek-V3\",\n",
    "    \"granite-3.1-8b-instruct\",\n",
    "    \"hammer2.1-7b\", \n",
    "    \"watt-tool-8b\", \n",
    "    \"qwen2.5-7b-instruct\", \n",
    "    \"qwen2.5-72b-instruct\",\n",
    "    \"gpt-4o\",\n",
    "]\n",
    "model_names_nl2sql=[\"llama-3-3-70b-instruct\",\"Llama-3.1-8B-Instruct\",\"Mixtral-8x22B-Instruct-v0.1\",\"DeepSeek-V3\",\"granite-3.1-8b-instruct\"]\n",
    "model_names_agents=[\"llama-3-3-70b-instruct\",\"Mixtral-8x22B-Instruct-v0.1\",\"gpt-4o\"]\n",
    "INTENT_COL = \"intent_list_metrics\"\n",
    "SLOT_COL = \"slot_set_metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_standardize_map={\n",
    "    \"llms\":\"llm\",\n",
    "    \"agents\":\"agent\",\n",
    "    \"llama-3-3-70b-instruct\": \"llama-3-3\",\n",
    "    \"Llama-3.1-8B-Instruct\": \"llama-3-1\",\n",
    "    \"Mixtral-8x22B-Instruct-v0.1\": \"mixtral-22b\",\n",
    "    \"gpt-4o\":\"gpt-4o\",\n",
    "    \"gpt4o\":\"gpt-4o\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(data,category=None,group=None,model=None):\n",
    "    if category == 'llms':\n",
    "        # if group=='rest':\n",
    "        #     pdb.set_trace()\n",
    "        #     intent_metrics = data[\"aggregated_metrics_problem_level\"][\"compute_mode_meta_metrics\"][INTENT_COL][\"micro\"][name_standardize_map[category]]\n",
    "        #     slot_metrics = data[\"aggregated_metrics_problem_level\"][\"compute_mode_meta_metrics\"][SLOT_COL][\"micro\"][name_standardize_map[category]]\n",
    "        # else:\n",
    "        intent_metrics = data[\"aggregated_metrics_problem_level\"][name_standardize_map[category]][INTENT_COL][\"micro\"][model.lower()]\n",
    "        slot_metrics = data[\"aggregated_metrics_problem_level\"][name_standardize_map[category]][SLOT_COL][\"micro\"][model.lower()]\n",
    "    elif category=='agents':\n",
    "        if group=='rest':\n",
    "            intent_metrics = data[\"aggregated_metrics_problem_level\"][\"compute_mode_meta_metrics\"][INTENT_COL][\"micro\"][\"llm\"]\n",
    "            slot_metrics = data[\"aggregated_metrics_problem_level\"][\"compute_mode_meta_metrics\"][SLOT_COL][\"micro\"][\"llm\"]\n",
    "        else:\n",
    "            try:\n",
    "                if model.lower() == \"gpt-4o\" and \"gpt4o\" in data[\"aggregated_metrics_problem_level\"][\"llm\"][INTENT_COL][\"micro\"].keys():\n",
    "                        intent_metrics = data[\"aggregated_metrics_problem_level\"][\"llm\"][INTENT_COL][\"micro\"][\"gpt4o\"]\n",
    "                        slot_metrics = data[\"aggregated_metrics_problem_level\"][\"llm\"][SLOT_COL][\"micro\"][\"gpt4o\"]\n",
    "                else:\n",
    "                    intent_metrics = data[\"aggregated_metrics_problem_level\"][\"llm\"][INTENT_COL][\"micro\"][model.lower()]\n",
    "                    slot_metrics = data[\"aggregated_metrics_problem_level\"][\"llm\"][SLOT_COL][\"micro\"][model.lower()]\n",
    "            except:\n",
    "                print(\"Trying model: \", model.lower())\n",
    "                print(\"Only found models: \", data[\"aggregated_metrics_problem_level\"][\"llm\"][INTENT_COL][\"micro\"].keys())\n",
    "                raise\n",
    "    return intent_metrics, slot_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(foldername,model_name=None):\n",
    "    filename=None\n",
    "    for file in os.listdir(foldername):\n",
    "        if \"metrics_aggregation\" in file:\n",
    "            if not model_name:\n",
    "                filename=os.path.join(foldername,file)\n",
    "                break\n",
    "            elif model_name in file:\n",
    "                filename=os.path.join(foldername,file)                \n",
    "                break\n",
    "\n",
    "    if not filename:\n",
    "        print(f\"No file named 'metrics_aggregation' in folder {foldername}\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Processing ---- {filename}\")\n",
    "        data = json.load(open(filename, 'r'))  \n",
    "        return data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(groups,model_names):\n",
    "    row_names=[]\n",
    "    col_names=[]\n",
    "    for i in groups:\n",
    "        for j in model_names:\n",
    "            row_names.append(i+\"==\"+j)\n",
    "    for i in ['intent','slot']:\n",
    "        for j in ['precision','recall','F1']:\n",
    "            col_names.append(i+\"_\"+j)\n",
    "    return pd.DataFrame(columns=col_names, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for LLMs\n",
    "category=\"llms\"\n",
    "results_llms=get_results_df(groups=groups,model_names=model_names_llms)\n",
    "for group in groups:\n",
    "    for model in model_names_llms:\n",
    "        data=None\n",
    "        if group ==\"rest\":\n",
    "            foldername=os.path.join(results_folder,str(category),str(group),str(version)+'/output/aggr/metrics_aggregation/')\n",
    "            # foldername=os.path.join(results_folder,str(category),str(group),str(version)+'/output/aggr/'+str(model.lower())+'/metrics_aggregation/')\n",
    "        else:\n",
    "            foldername=os.path.join(results_folder,str(category),str(group))\n",
    "        \n",
    "        if os.path.isdir(foldername):\n",
    "            data = get_data(foldername=foldername)\n",
    "        else:\n",
    "            print(f\"{foldername} doesnot exist\")\n",
    "        if data:\n",
    "            intent_metrics, slot_metrics = get_metrics(data,category=category,group=group,model=model)\n",
    "            results_llms.loc[group+'=='+model]=[round(intent_metrics['precision'],2) if isinstance(intent_metrics['precision'],float) else intent_metrics['precision'],\n",
    "                                                round(intent_metrics['recall'],2) if isinstance(intent_metrics['recall'],float) else intent_metrics['recall'],\n",
    "                                                round(intent_metrics['f1'],2) if isinstance(intent_metrics['f1'],float) else intent_metrics['f1'],\n",
    "                                                round(slot_metrics['precision'],2) if isinstance(slot_metrics['precision'],float) else slot_metrics['precision'],\n",
    "                                                round(slot_metrics['recall'],2) if isinstance(slot_metrics['recall'],float) else slot_metrics['recall'],\n",
    "                                                round(slot_metrics['f1'],2) if isinstance(slot_metrics['f1'],float) else slot_metrics['f1']]\n",
    "results_llms = results_llms.add_prefix(f'{category}_')\n",
    "print(f\"-------------------------------{category}-------------------------------------\")\n",
    "print(results_llms)\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Win Rates for LLMs\n",
    "category=\"llms\"\n",
    "results_llms[\"llms_win_rate\"] = None\n",
    "for group in groups:\n",
    "    if group == \"rest\":\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(version),\"output/\"+str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))        \n",
    "    else:\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))\n",
    "    data =  {k.lower(): v for k, v in data.items()}\n",
    "    for model in model_names_llms:\n",
    "        if model.lower() in data.keys():\n",
    "            win_rate=data[model.lower()][\"total_micro\"][\"win_rate\"]\n",
    "            results_llms.loc[str(group)+\"==\"+str(model),\"llms_win_rate\"] = round(win_rate,2) if isinstance(win_rate,float) else win_rate\n",
    "        else:\n",
    "            results_llms.loc[str(group)+\"==\"+str(model),\"llms_win_rate\"]=\"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for Agents\n",
    "category=\"agents\"\n",
    "results_agents=get_results_df(groups=groups,model_names=model_names_agents)\n",
    "for group in groups:\n",
    "    for model in model_names_agents:\n",
    "        data=None\n",
    "        if group ==\"rest\":\n",
    "            foldername=os.path.join(results_folder,str(category),str(group),str(version)+'/aggr/'+str(name_standardize_map[model])+'/metrics_aggregation/')\n",
    "            if os.path.isdir(foldername):\n",
    "                data = get_data(foldername=foldername)\n",
    "            else:\n",
    "                print(f\"{foldername} doesnot exist\")\n",
    "        else:\n",
    "            foldername=os.path.join(results_folder,str(category),str(group))\n",
    "            data = get_data(foldername=foldername)\n",
    "        \n",
    "        if data:\n",
    "            intent_metrics, slot_metrics = get_metrics(data,category=category,group=group,model=model)\n",
    "            results_agents.loc[group+'=='+model]=[round(intent_metrics['precision'],2) if isinstance(intent_metrics['precision'],float) else intent_metrics['precision'],\n",
    "                                                round(intent_metrics['recall'],2) if isinstance(intent_metrics['recall'],float) else intent_metrics['recall'],\n",
    "                                                round(intent_metrics['f1'],2) if isinstance(intent_metrics['f1'],float) else intent_metrics['f1'],\n",
    "                                                round(slot_metrics['precision'],2) if isinstance(slot_metrics['precision'],float) else slot_metrics['precision'],\n",
    "                                                round(slot_metrics['recall'],2) if isinstance(slot_metrics['recall'],float) else slot_metrics['recall'],\n",
    "                                                round(slot_metrics['f1'],2) if isinstance(slot_metrics['f1'],float) else slot_metrics['f1']]\n",
    "results_agents = results_agents.add_prefix(f'{category}_')\n",
    "print(f\"-------------------------------{category}-------------------------------------\")\n",
    "print(results_agents)\n",
    "print(\"------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Win Rates for Agents\n",
    "category=\"agents\"\n",
    "results_agents[\"agents_win_rate\"] = None\n",
    "for group in groups:\n",
    "    if group == \"rest\":\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(version),str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))        \n",
    "    else:\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))\n",
    "        if \"gpt4o\" in data.keys():\n",
    "            data[\"gpt-4o\"] = data[\"gpt4o\"]\n",
    "    for model in model_names_agents:\n",
    "        if (name_standardize_map[model] in data.keys()):\n",
    "            win_rate=data[name_standardize_map[model]][\"total_micro\"][\"win_rate\"]\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"agents_win_rate\"] = round(win_rate,2) if isinstance(win_rate,float) else win_rate\n",
    "        else:\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"agents_win_rate\"]=\"None\"\n",
    "\"\"\"\n",
    "## Win Rates for Agents\n",
    "category=\"agents\"\n",
    "results_agents[\"agents_win_rate\"] = None\n",
    "for group in groups:\n",
    "    if group == \"rest\":\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(version),str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))        \n",
    "    else:\n",
    "        filename = os.path.join(results_folder,str(category),str(group),str(group)+\"_win_rates.json\")\n",
    "        data=json.load(open(filename, 'r'))\n",
    "        if \"gpt4o\" in data.keys():\n",
    "            data[\"gpt-4o\"] = data[\"gpt4o\"]\n",
    "    for model in model_names_agents:\n",
    "        if (name_standardize_map[model] in data.keys()):\n",
    "            win_rate=data[name_standardize_map[model]][\"total_micro\"][\"win_rate\"]\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"agents_win_rate\"] = round(win_rate,2)\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"base_llm_win_rate\"] = results_llms.loc[str(group)+\"==\"+str(model),\"llms_win_rate\"]\n",
    "            tao_length=data[name_standardize_map[model]][\"total_micro\"].get(\"avg_loops\", -1)\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"agents_tao_length\"] = round(tao_length,2)\n",
    "        else:\n",
    "            results_agents.loc[str(group)+\"==\"+str(model),\"agents_win_rate\"]=\"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add win rates\n",
    "results_llms = results_llms.fillna(\"None\")\n",
    "results_agents = results_agents.fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged Results\n",
    "results = results_llms.join(results_agents).fillna(\"-\")\n",
    "results=results.replace(\"None\",\"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Add NL2SQL win rates\n",
    "# category=\"nl2sql\"\n",
    "# results[\"nl2sql_win_rate\"]=None\n",
    "# for group in groups:\n",
    "#     filename = os.path.join(results_folder,str(category),str(group),\"metrics_aggregation.json\")\n",
    "#     data=json.load(open(filename, 'r'))\n",
    "#     for model in model_names_nl2sql:\n",
    "#         win_rate=data[model][\"answer_rate\"]\n",
    "#         print(model,win_rate)\n",
    "#         results.loc[str(group)+\"==\"+str(model),\"nl2sql_win_rate\"] = round(win_rate,2) if isinstance(win_rate,float) else win_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Fix based on final decision\n",
    "naming_map={\n",
    "    \"slot_filling\":\"SLOT-BIRD\",\n",
    "    \"sequencing\":\"SEL-BIRD\",\n",
    "    \"rest\":\"REST-BIRD\",\n",
    "    \"llama-3-3-70b-instruct\":\"Llama-3-3-70b-Inst\",\n",
    "    \"Llama-3.1-8B-Instruct\":\"Llama-3.1-8B-Inst\",\n",
    "    \"Mixtral-8x22B-Instruct-v0.1\":\"Mixtral-8x22B-Inst\",\n",
    "    \"DeepSeek-V3\":\"DeepSeek-V3\",\n",
    "    \"granite-3.1-8b-instruct\":\"Granite-3.1-8b-Inst\",\n",
    "    \"hammer2.1-7b\":\"Hammer2.1-7b\",\n",
    "    \"qwen2.5-7b-instruct\":\"Qwen2.5-7b-Inst\",\n",
    "    \"watt-tool-8b\":\"Watt-tool-8b\", \n",
    "    'qwen2.5-72b-instruct':\"Qwen2.5-72b-Inst\",\n",
    "    \"gpt-4o\":\"gpt-4o\",\n",
    "    }\n",
    "num='{1}'\n",
    "type='{c}'\n",
    "val=\"{}\"\n",
    "category=\"\"\n",
    "for idx, row in enumerate(results_llms.iterrows()):\n",
    "    model = naming_map[row[0].split(\"==\")[1]]\n",
    "    row_text=f\" & {model}\"\n",
    "    if category != naming_map[row[0].split(\"==\")[0]]:\n",
    "        category=naming_map[row[0].split(\"==\")[0]]\n",
    "        print(f\"-------------------------------------------------{category}-------------------------------------------------\")\n",
    "    #     val=\"{\"+category+\"}\"\n",
    "    #     # row_text=f\"\\multicolumn{num}{type}{val} & {model}\"\n",
    "    #     row_text=f\"{model}\"        \n",
    "    # else:\n",
    "    #     val=\"{}\"\n",
    "    #     # row_text=f\"\\multicolumn{num}{type}{val} & {model}\"\n",
    "    #     row_text=f\"{model}\"        \n",
    "    \n",
    "    for i, item in enumerate(row[1]):\n",
    "        item = \"{\"+str(item)+\"}\"\n",
    "        row_text+= f\" & {item} \"\n",
    "        if i == (len(row[1])-1):\n",
    "            row_text+=\"\\\\\\\\\"\n",
    "    print(row_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agents table\n",
    "\n",
    "## TODO : Fix based on final decision\n",
    "naming_map={\n",
    "    \"slot_filling\":\"SLOT-BIRD\",\n",
    "    \"sequencing\":\"SEL-BIRD\",\n",
    "    \"rest\":\"REST-BIRD\",\n",
    "    \"llama-3-3-70b-instruct\":\"Llama-3-3-70b-Inst\",\n",
    "    \"Llama-3.1-8B-Instruct\":\"Llama-3.1-8B-Inst\",\n",
    "    \"Mixtral-8x22B-Instruct-v0.1\":\"Mixtral-8x22B-Inst\",\n",
    "    \"DeepSeek-V3\":\"DeepSeek-V3\",\n",
    "    \"granite-3.1-8b-instruct\":\"Granite-3.1-8b-Inst\",\n",
    "    \"hammer2.1-7b\":\"Hammer2.1-7b\",\n",
    "    \"qwen2.5-7b-instruct\":\"Qwen2.5-7b-Inst\",\n",
    "    \"watt-tool-8b\":\"Watt-tool-8b\", \n",
    "    'qwen2.5-72b-instruct':\"Qwen2.5-72b-Inst\",\n",
    "    \"gpt-4o\":\"gpt-4o\",\n",
    "    }\n",
    "num='{1}'\n",
    "type='{c}'\n",
    "val=\"{}\"\n",
    "category=\"\"\n",
    "results_agents = results_agents[['base_llm_win_rate', 'agents_win_rate', 'agents_tao_length']]\n",
    "for idx, row in enumerate(results_agents.iterrows()):\n",
    "    model = naming_map[row[0].split(\"==\")[1]]\n",
    "    row_text=f\"{model}\"\n",
    "    if category != naming_map[row[0].split(\"==\")[0]]:\n",
    "        category=naming_map[row[0].split(\"==\")[0]]\n",
    "        print(f\"-------------------------------------------------{category}-------------------------------------------------\")\n",
    "    #     val=\"{\"+category+\"}\"\n",
    "    #     # row_text=f\"\\multicolumn{num}{type}{val} & {model}\"\n",
    "    #     row_text=f\"{model}\"        \n",
    "    # else:\n",
    "    #     val=\"{}\"\n",
    "    #     # row_text=f\"\\multicolumn{num}{type}{val} & {model}\"\n",
    "    #     row_text=f\"{model}\"        \n",
    "    \n",
    "    for i, item in enumerate(row[1]):\n",
    "        item = \"{\"+str(item)+\"}\"\n",
    "        row_text+= f\" & {item} \"\n",
    "        if i == (len(row[1])-1):\n",
    "            row_text+=\"\\\\\\\\\"\n",
    "    print(row_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\begin{table}[]\n",
    "# \\scriptsize\n",
    "# \\begin{tabular}{lcllllllllllllll}\n",
    "#                               & \\multicolumn{1}{l}{} & \\multicolumn{7}{c}{Direct Invocation}                                                                                                                                          & \\multicolumn{7}{c}{ReACT Agent}                                                                                                                            \\\\\n",
    "# \\multicolumn{1}{c}{Dataset}   & Model                & \\multicolumn{3}{c}{Intent}                                             & \\multicolumn{3}{c}{Slot}                                               & \\multicolumn{1}{c}{Win Rate} & \\multicolumn{3}{c}{Intent}                                             & \\multicolumn{3}{c}{Slot}                                               & Win Rate \\\\\n",
    "# \\multicolumn{1}{c}{}          &                      & \\multicolumn{1}{c}{P} & \\multicolumn{1}{c}{R} & \\multicolumn{1}{c}{F1} & \\multicolumn{1}{c}{P} & \\multicolumn{1}{c}{R} & \\multicolumn{1}{c}{F1} &                              & \\multicolumn{1}{c}{P} & \\multicolumn{1}{c}{R} & \\multicolumn{1}{c}{F1} & \\multicolumn{1}{c}{P} & \\multicolumn{1}{c}{R} & \\multicolumn{1}{c}{F1} &          \\\\\n",
    "# \\multicolumn{1}{c}{SLOT-BIRD} & M1                   & \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}   & \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{}   &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "# \\multicolumn{1}{c}{}          & M2                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "# \\multicolumn{1}{c}{}          & M3                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "# SEL-BIRD                      & M1                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "#                               & M2                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "#                               & M3                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "# REST-BIRD                     & M1                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &          \\\\\n",
    "#                               & M2                   &                       &                       &                        &                       &                       &                        &                              &                       &                       &                        &                       &                       &                        &         \n",
    "# \\end{tabular}\n",
    "# \\label{tab:main-results}\n",
    "# \\todo{Since we dont have all models as agents may need to break? }\n",
    "# \\caption{Performance of Models and ReACT Agents on our dataset}\n",
    "# \\end{table}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "invoke",
   "language": "python",
   "name": "invoke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
